{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c34424-01a8-4472-a654-4db8f13d57ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\jkutty\\Lib\\site-packages\\trulens_eval\\utils\\imports.py:573: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  return self.imp(name, globals, locals, fromlist, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "‚úÖ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deepa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import openai\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be5a8f0-c1ad-463f-b766-31e958ee79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1354cdac-8b3a-4948-8232-d78bf2aef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%s Tru initialized with db url %s . ü¶ë sqlite:///default.sqlite\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffabef66-a043-4f82-bb30-8be8ab685dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./Josekutty_Jose_ML_Resume.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ecfc01-2f1e-4174-9128-768997c83a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3375b06-fec6-45f2-8f1e-feca3903c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josekutty Jose\\nMachine Learning Engineer\\n‚ôÇphone+91 9745949352 /envel‚å¢pejosekuttyjose08@gmail.com /linkedinLinkedIn /githubGitHub DagsHub·Ωë7LeetCode\\nProÔ¨Åle Summary\\nHighly motivated Machine Learning Engineer over 6+ months of experience in Generative AI with a passion for building\\nimpactful AI solutions. Proven ability to design, develop, and deploy machine learning models across various domains.\\nSkilled in data preprocessing, feature engineering, model selection, and hyperparameter tuning . Experience working with\\nTensorFlow, PyTorch, and scikit-learn and Expertise in Quantization, Fine -tuning and improving the models performance.\\nEager to contribute to a team environment and continuously learn new technologies.\\nTechnical Skills\\nLanguages : Python, HTML, SQL, CSS, Neo4j, Cypher\\nFrameworks : TensorÔ¨Çow, Langchain, Streamlit, Pytorch , Fastapi\\nLibraries : Excel, Pandas, Numpy, Scipy, Scikit-learn\\nTools & Platforms : Git, Dagshub,\\nData Visualization : Power BI, Tableau , Matplotlib, Seaborn\\nDomain Skills : NLP, Statistical Modeling, Predictive Modeling, Data Analysis, Transformers, Machine Learning, Web\\nScraping, Generative AI, Deep Learning, CNN,Computer Vision, ArtiÔ¨Åcial General Intelligence, AI\\nProjects\\nDetecting Air pollution in Mongolia using NLP |Apify, T5 Bert , LSTM, Deberta LLM, Hugging Face DagsHub\\n‚Ä¢Collaborated with a 23- member team to develop and implement Environmental Sentinel on Social Media using\\nsentiment analysisf or real-time air pollution monitoring in Mongolia.\\n‚Ä¢Applied 3 key techniques: Market Research ,Data Collection , and Preprocessing , leading to successful Model\\nDevelopment\\n‚Ä¢Successfully scraped and collected 75,469 pieces of Mongolian text from diverse sources, including Mongolian social\\nmedia platforms and news channels.\\n‚Ä¢Achieved sentiment analysis using LSTM with a focus on eÔ¨Éciency, utilizing minimal epochs due to lengthy\\nprocessing time. Applied both categorical cross-entropy and binary cross-entropy loss functions, yielding 85%\\naccuracy for categorical loss and 55% for binary loss.\\n‚Ä¢Leveraged advanced LoRA techniques to Ô¨Åne-tune LLM model, resulting in a remarkable 4%increase in accuracy\\nwithin a mere 3training epochs.\\nInterview Preparation Chatbot: |gtts , speech recognition , Chroma, DuckDB, Gemini. Live |DagsHub\\n‚Ä¢Collaborated with a team of 30to develop a Chatbot web application for Interview preparation.\\n‚Ä¢Collected 7000 questions and answers from diÔ¨Äerent sources for Non technical Jobs using Beautiful Soup(Web\\nScraping).\\n‚Ä¢Implemented Speech Recognition technology to enable seamless interaction, enhancing the user experience\\nthrough voice driven commands and responses using gttsand speech recognition.\\n‚Ä¢Implemented RAG (Retrieval-Augmented Generation) with Chroma and DuckDB as vector databases for eÔ¨Écient\\nretrieval\\n‚Ä¢The answers were evaluated using the vector similarity check.\\nGemInsights: AI Automated Analyst |Autoviz, Gemini, llama index, Trulens Live |GitHub\\n‚Ä¢Collaborated with a team of 6during a Gemini hackathon organized by LabLab, developing an automatic EDA\\n(Exploratory Data Analysis) application using Gemini models.\\n‚Ä¢Generated Insights from 7visualizations about the data and provide clarity in decision making\\n‚Ä¢Evaluated the answers from the LLMs using Trulens .\\n‚Ä¢The project were selected as the most upvoted project in the Gemini Hackathon.\\n\\nPersonal Projects\\nGenEye: Your Mental Health Assistant |llama2, langchain , speech recognition, gtts, Qlora, Peft, Chroma Github\\n‚Ä¢Conversational Chatbot built Large Language Model llama2 and Langchain as Framework for visually impaired\\npeople.\\n‚Ä¢Used Libraries like speech recognition and gtts for identifying speech and converting the text to speech which can\\nbe accessed by any type of people.\\n‚Ä¢Model Ô¨Åne-tuned on Mental Health Dataset using Qlora and Peft.\\nRoad Accident Dashboard |Tableau Link\\n‚Ä¢Developed a comprehensive road accident dashboard using Tableau to analyze 2019 - 2022 accident data and\\nimprove decision-making processes.\\n‚Ä¢Categorized accidents by 3 levels of severity and used visualizations to delve into the factors contributing to severe\\naccidents.\\n‚Ä¢Conducted comparative analyses of accident statistics across regions and time periods, facilitating the assessment of\\nsafety measures and interventions.\\nExperience\\nOmdena Nov 2023 ‚Äì Present\\nJunior Machine Learning Engineer Remote\\n‚Ä¢Collaborated with 25+ AI Engineers, developers and clients in remote settings, ensuring seamless project execution\\nand delivery of AI applications or products which solves real word problems.\\n‚Ä¢Done web scraping using beautiful soup and Apify to collect 100,000 data from diÔ¨Äerent sources to create dataset\\nfor quality prediction.\\n‚Ä¢Used Hugging face models like facebook/bart-large-mnli (zero-shot classiÔ¨Åcation ) and used language translation\\nmodels like T-5,Bert and Deberta llm.\\n‚Ä¢Implemented gtts and speech recognition models like whisper for better user experience and interaction.\\nEducation\\nData Science using python Dec 2023 - Jan 2024\\nBrototype Ernakulam, Kerala\\nBig data data Science using python and AWS Jan 2022 - Aug 2022\\nLuminar Technolab Ernakulam, Kerala\\nB.com with Logistics and Supply Chain , CGPA : 6 2018 - 2021\\nKristu Jayanti College Bangalore, Karnataka'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f276d180-320b-4415-806b-eedbda1bc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e461e45-54c2-4805-85df-85be9c4c319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = \\\n",
    "get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48045b64-a4e3-41c1-91e7-98ee7e91f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He can apply for jobs related to Machine Learning Engineering, Generative AI, NLP, Statistical Modeling, Predictive Modeling, Data Analysis, Transformers, Deep Learning, Computer Vision, and Artificial General Intelligence.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sentence_window_engine.query(\n",
    "    \"What kind of jobs he can actually apply for\")\n",
    "output.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94531a9-72f0-4c12-9bbe-07e114056bc8",
   "metadata": {},
   "source": [
    "### Feedback Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa434fcf-cbc2-4c95-8c5f-cc248144ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c583af-a44f-4ce7-b003-c91cc7e7e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import OpenAI as fOpenAI\n",
    "\n",
    "provider = fOpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf05e69-a42d-44e9-bf14-0a93de294aad",
   "metadata": {},
   "source": [
    "### Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db44dba5-f6e0-4b3d-beaf-0b218a1a64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback\n",
    "\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99ad2f-8bc6-4541-8905-ad867974c5fb",
   "metadata": {},
   "source": [
    "### Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a14cb4f-2ab7-4aea-afcb-b5fd89dbaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "\n",
    "context_selection = TruLlama.select_source_nodes().node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6efd8e29-19f4-45b0-912f-88fabd083cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "487c8ce7-c310-4859-8802-194ecd860c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "‚úÖ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance_with_cot_reasons,\n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a03c5-c1a8-4c97-929c-c1b8b1adecc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
